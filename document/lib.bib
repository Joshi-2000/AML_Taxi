@misc{floydhubIntroductionQLearning,
	author = {},
	title = {{A}n introduction to {Q}-{L}earning: {R}einforcement {L}earning --- blog.floydhub.com},
	howpublished = {\url{https://blog.floydhub.com/an-introduction-to-q-learning-reinforcement-learning/}},
	year = {},
	note = {[Accessed 27-Feb-2023]},
}
@misc{mediumQLearningLets,
	author = {Thomas Simonini},
	title = {{Q}-{L}earning, lets create an autonomous {T}axi ({P}art 2/2) --- thomassimonini.medium.com},
	howpublished = {\url{https://thomassimonini.medium.com/q-learning-lets-create-an-autonomous-taxi-part-2-2-8cbafa19d7f5}},
	year = {},
	note = {[Accessed 24-Feb-2023]},
}

@misc{mediumTemporalDifference,
	author = {Sjoerd Vink},
	title = {{T}emporal {D}ifference {L}earning: {S}{A}{R}{S}{A} vs {Q}-{L}earning --- sjoerdvink.medium.com},
	howpublished = {\url{https://sjoerdvink.medium.com/temporal-difference-learning-sarsa-vs-q-learning-c367934b8bcc}},
	year = {2022},
	note = {[Accessed 26-Feb-2023]},
}
@misc{towardsdatascienceReinforcementLearning,
	author = {Saul Dobilas},
	title = {{R}einforcement {L}earning with {S}{A}{R}{S}{A}â€”{A} {G}ood {A}lternative to {Q}-{L}earning {A}lgorithm --- towardsdatascience.com},
	howpublished = {\url{https://towardsdatascience.com/reinforcement-learning-with-sarsa-a-good-alternative-to-q-learning-algorithm-bf35b209e1c#}},
	year = {},
	note = {[Accessed 28-Feb-2023]},
}
@misc{builtinUnderstandingMarkov,
	author = {},
	title = {{U}nderstanding the {M}arkov {D}ecision {P}rocess ({M}{D}{P}) --- builtin.com},
	howpublished = {\url{https://builtin.com/machine-learning/markov-decision-process}},
	year = {},
	note = {[Accessed 26-Feb-2023]},
}
@misc{towardsdatascienceExplorationReinforcement,
	author = {Ziad SALLOUM},
	title = {{E}xploration in {R}einforcement {L}earning --- towardsdatascience.com},
	howpublished = {\url{https://towardsdatascience.com/exploration-in-reinforcement-learning-e59ec7eeaa75#}},
	year = {},
	note = {[Accessed 27-Feb-2023]},
}
@misc{mediumReinforcementLearningPolicyValue,
	author = {Sebastian Dittert},
	title = {{R}einforcement {L}earning: {V}alue {F}unction and {P}olicy --- medium.com},
	howpublished = {\url{https://medium.com/analytics-vidhya/reinforcement-learning-value-function-and-policy-c22f5bd1d1b0#}},
	year = {},
	note = {[Accessed 25-Feb-2023]},
}
@misc{mediumBeginnersGuide,
	author = {Tanvi Penumudy},
	title = {{A} {B}eginners {G}uide to {R}einforcement {L}earning and its {B}asic {I}mplementation from {S}cratch --- medium.com},
	howpublished = {\url{https://medium.com/analytics-vidhya/a-beginners-guide-to-reinforcement-learning-and-its-basic-implementation-from-scratch-2c0b5444cc49}},
	year = {},
	note = {[Accessed 24-Feb-2023]},
}
@misc{lesswrongWhatTraining,
	author = {},
	title = {{W}hat is a training "step" vs. "episode" in machine learning? - {L}ess{W}rong --- lesswrong.com},
	howpublished = {\url{https://www.lesswrong.com/posts/jXbrx7kfA4XHswfcu/what-is-a-training-step-vs-episode-in-machine-learning}},
	year = {},
	note = {[Accessed 23-Feb-2023]},
}
@misc{datasolutReinforcementLearning,
	author = {Laurenz Wuttke},
	title = {{R}einforcement {L}earning: {W}enn {K}{I} auf {B}elohnungen reagiert --- datasolut.com},
	howpublished = {\url{https://datasolut.com/reinforcement-learning/}},
	year = {},
	note = {[Accessed 27-Feb-2023]},
}
@misc{v7labsReinforcementLearning,
	author = {},
	title = {9 {R}einforcement {L}earning {R}eal-{L}ife {A}pplications --- v7labs.com},
	howpublished = {\url{https://www.v7labs.com/blog/reinforcement-learning-applications}},
	year = {},
	note = {[Accessed 25-Feb-2023]},
}




