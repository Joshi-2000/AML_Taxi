\section{Zusammenfassung und Ausblick}

Im Rahmen der Arbeit konnte sich ausgiebig mit den Grundlagen des Reinforcement Learnings auseinandergesetzt werden. Es wurde anhand von drei einfacheren Szenarien zwei klassische Algorithmen für das Temporal Difference Learning getestet.
Für die beiden Algorithmen gibt es eine Vielzahl von Parametern, welche je nach Anwendungsfall passend gewählt werden müssen. Im Rahmen der Arbeit konnten die Einflüsse dieser Parameter aufgezeigt werden. Für die Temporal Difference Learning Algorithmen Q-Learning und SARSA konnte ein ausführlicher Vergleich anhand der drei Probleme durchgeführt werden.
Hierbei wurde festgestellt, dass die Algorithmen je nach Problem zu unterschiedlichen Ergebnissen führen. So hat das Q-Learning beim Taxi Problem etwas besser abgeschnitten, während SARSA den wohl sichereren Weg bei dem Cliff Problem gewählt hat. \\

In weiteren  Arbeiten ist es von Interesse, sich mit komplexeren Problemen und dem Thema Deep Reinforcement Learning zu beschäftigen. Dies ermöglicht das Anwenden von Reinforcement Learning auf weitaus komplexere Herausforderungen, welche nur schwer mit den in dieser Arbeit genutzten Algorithmen lösbar sind.